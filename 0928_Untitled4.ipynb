{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d1327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ã€2022Â·å¹´åº¦çˆ±ç”¨ç‰©ğŸ†å½©å¦†ç¯‡ã€‘è¶…é•¿25minå®Œæ•´ç‰ˆï¼20å¤§å“ç±»ï¼100+ä»¶çˆ±ç”¨ç²¾é€‰ï¼ä¸€è·¯å¸¸...\n",
      "1        ã€Šäº‘ä¹‹ç¾½ã€‹åŸç­é€ å‹å›¢é˜ŸğŸ¬      ğŸŒŸ#è™ä¹¦æ¬£äº‘ä¸ºè¡«å¦†é€ è¿˜åŸ#ãŠ™ï¸è™ä¹¦æ¬£æœ¬å‰§å¾¡ç”¨åŒ–å¦†å¸ˆ@ä¾æ…§...\n",
      "2        è°æ‡‚ï¼ï¼ğŸ˜­æ¬£æ¬£æŠŠäº‘ä¸ºè¡«çš„å‰§ç»„è¡£æœå€Ÿæˆ‘ç©¿äº†ï¼ï¼ï¼#è™ä¹¦æ¬£äº‘ä¸ºè¡«å¦†é€ è¿˜åŸ##å¾®åšå˜ç¾æ‰‹å†Œ# #ä»¿...\n",
      "3            å›å®¶å•¦ï¼é¥­åæ•£æ­¥ä¸­~ç‰¹åˆ«èˆ’æœçš„åˆç§‹ä¸Šæµ·ï¼ğŸ’¨ğŸ‚#ä¸€æå—å—[è¶…è¯]# Â [ç»„å›¾å…±6å¼ ]Â åŸå›¾Â \n",
      "4        9æœˆç¬¬ä¸€å¤©ï¼ï¼æ°´é€†é€€æ•£ï¼ï¼æ¥æ¥å¥½è¿ğŸ€ğŸâ€”â€”â€”â€”å›ºå®šæ ç›®ã€Œprç¤¼ç‰©ã€ä¸Šçº¿ï½è¯„è®ºåŒºè®¸æ„¿æ± å¼€æ”¾âœŒğŸ»...\n",
      "                               ...                        \n",
      "13000    ğ™‰ğ™ğ™˜ğ™š ğ™©ğ™¤ ğ˜¾ ğ™®ğ™¤ğ™ªç°åœºåšå®éªŒçš„ä¸€å¤©ğŸ”…#ç¾å¦†ç”Ÿæ´»##motd##å¥½ç‰©åˆ†äº«# Â [ç»„å›¾å…±...\n",
      "13001    ğ™„ğ™‰ğ™ğ™Šğ™‰ğ™€ ğ™€ğ˜¿ğ™„ğ™ğ™„ğ™Šğ™‰_å¿ƒæ…•ä¸ä½ è‰²å½©ç¼–è¾‘éƒ¨å®ä¹ ç¼–è¾‘ä¸Šçº¿ğŸ’—#2023çš„å¥¹ä»¬##åŠ¨é™çš†é£å°š...\n",
      "13002    æœ€è¿‘å¤©æ°”å¤ªå¥½å•¦ï½åˆ°å¤„éƒ½æ˜¯æ˜¥æ—¥çš„ä¿¡å·ğŸŒ¿â˜ï¸#2023çš„å¥¹ä»¬##ç¾å¦†ç”Ÿæ´»##åŠ¨é™çš†é£å°š# Â [ç»„...\n",
      "13003    å•¾å’ªï¼Ê™ÊŸá´œá´‡ Ê™ÊŸá´œá´‡çš®é—ªç°ğŸ’™ä»Šå¤©æ‰“å¡äº†ç§‘é¢œæ°ã€Œè¶…CHILLã€ä¿æ¹¿è¡—åŒºï¼è¶…å¤šçš„æ²‰æµ¸å¼ä½“éªŒåœº...\n",
      "13004    ã€Šå…³äºç›¸å†Œé‡Œçš„å›¤å›¾è¿™ä»¶äº‹ã€‹âœ è¿Ÿåˆ°çš„âŒæœˆá´˜ÊŸá´É¢è¯·æŸ¥æ”¶ âœ“#2023çš„å¥¹ä»¬##æ—¥å¸¸ç¢ç‰‡plo...\n",
      "Name: å¾®åšæ­£æ–‡, Length: 13005, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# æŒ‡å®šæ–‡ä»¶è·¯å¾„\n",
    "file_path = '/Users/laihuiqian/Documents/weibo_0925/total1-0925.csv'\n",
    "\n",
    "# è¯»å–.csvæ–‡ä»¶åˆ°DataFrame\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# æå–â€œå¾®åšæ­£æ–‡â€è¿™ä¸€åˆ—\n",
    "weibo_content = df[\"å¾®åšæ­£æ–‡\"]\n",
    "\n",
    "# æ‰“å°â€œå¾®åšæ­£æ–‡â€\n",
    "print(weibo_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430511ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "INFO:lda:n_documents: 13005\n",
      "INFO:lda:vocab_size: 5000\n",
      "INFO:lda:n_words: 298022\n",
      "INFO:lda:n_topics: 17\n",
      "INFO:lda:n_iter: 100\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -3646656\n",
      "INFO:lda:<10> log likelihood: -2656670\n",
      "INFO:lda:<20> log likelihood: -2514413\n",
      "INFO:lda:<30> log likelihood: -2461563\n",
      "INFO:lda:<40> log likelihood: -2437192\n",
      "INFO:lda:<50> log likelihood: -2424579\n",
      "INFO:lda:<60> log likelihood: -2415868\n",
      "INFO:lda:<70> log likelihood: -2408600\n",
      "INFO:lda:<80> log likelihood: -2403769\n",
      "INFO:lda:<90> log likelihood: -2398470\n",
      "INFO:lda:<99> log likelihood: -2397472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model done\n",
      "shape: (17, 5000)\n",
      "['00' '01' '02']\n",
      "[[4.61169526e-07 4.61169526e-07 4.61169526e-07]\n",
      " [9.30578820e-07 9.30578820e-07 9.30578820e-07]\n",
      " [6.23519142e-07 6.23519142e-07 6.23519142e-07]\n",
      " [5.79619626e-03 5.63245555e-04 5.62682872e-07]\n",
      " [5.73789305e-07 5.74363094e-04 1.03339454e-03]\n",
      " [8.65276456e-07 8.65276456e-07 8.65276456e-07]\n",
      " [5.98909984e-07 5.98909984e-07 5.98909984e-07]\n",
      " [4.25387102e-07 4.25387102e-07 4.25387102e-07]\n",
      " [1.05418511e-06 1.05418511e-06 1.05418511e-06]\n",
      " [5.16368894e-07 5.16368894e-07 5.16368894e-07]\n",
      " [6.83854202e-07 6.83854202e-07 3.42610955e-04]\n",
      " [5.21975154e-07 5.21975154e-07 5.21975154e-07]\n",
      " [3.20728696e-07 3.20728696e-07 3.20728696e-07]\n",
      " [4.31685733e-07 4.31685733e-07 4.31685733e-07]\n",
      " [6.36294222e-07 6.36294222e-07 6.36294222e-07]\n",
      " [6.03427468e-07 6.03427468e-07 6.03427468e-07]\n",
      " [1.05875714e-03 7.05367849e-07 7.05367849e-07]]\n",
      "topic: 0 sum: 0.9999999999999561\n",
      "topic: 1 sum: 0.9999999999999183\n",
      "topic: 2 sum: 0.9999999999999251\n",
      "topic: 3 sum: 1.0000000000000449\n",
      "topic: 4 sum: 0.9999999999998892\n",
      "topic: 5 sum: 0.9999999999999654\n",
      "topic: 6 sum: 0.9999999999999983\n",
      "topic: 7 sum: 0.999999999999892\n",
      "topic: 8 sum: 0.9999999999999358\n",
      "topic: 9 sum: 1.0000000000000822\n",
      "topic: 10 sum: 0.9999999999999512\n",
      "topic: 11 sum: 1.0000000000000262\n",
      "*Topic 0\n",
      "- å¦†å®¹ ä»Šæ—¥ ç¾å¦† look ootd æ°›å›´ ä»Šå¤© çœŸçš„ æ˜¥å­£ å‡ºè¡— æ˜¥å¤© å‡ºæ¸¸ æ˜¥å¤ çœ¼å¦† è¿™ä¸ª é€‚åˆ å¤æ—¥ æ˜¥æ—¥ å°±æ˜¯ åŒ–å¦†\n",
      "*Topic 1\n",
      "- äº’åŠ¨ å¤§å®¶ ç²‰ä¸ å¯ä»¥ è¯„è®º ç§ä¿¡ å®è´ ä½ ä»¬ æ—¥å¸¸ å¤šå¤š ç¦åˆ© ç¾å°‘å¥³ è®°å¾— æŠ½å¥– åŠ å…¥ ä¸€èµ· ç»§ç»­ ä¸Šæ¦œ éšæœº æ­å–œ\n",
      "*Topic 2\n",
      "- é¦™æ°´ å‘³é“ ç«ç‘° é¦™æ°” æ¸©æŸ” æ¸…æ–° é«˜çº§ æµªæ¼« æ„Ÿè§‰ æ°”æ¯ é€‚åˆ èŠ±é¦™ æœ¨è´¨ ä¸€æ¬¾ æ°›å›´ é¦™æ°› ç³»åˆ— é¦™å‘³ å–œæ¬¢ ç¾å¥½\n",
      "*Topic 3\n",
      "- é“¾æ¥ åœ°å›¾ æ˜¾ç¤º ä¸€èµ· è¿˜æœ‰ äº¬ä¸œ 11 è¶…çº§ æ´»åŠ¨ å¤©çŒ« ç¦åˆ© å·´é» ä¸Šæµ· æœç´¢ å“ç‰Œ è¶…å¤š 20 ç›´æ’­é—´ 10 è¿™æ¬¡\n",
      "*Topic 4\n",
      "- å£çº¢ å®Œç¾ æ”»ç•¥ å¼€æ˜¥ åˆ†äº« å¥½é¢œ è®¡åˆ’ æ–°å¹´ å¦†å®¹ åº•å¦† ç²‰åº•æ¶² çœ¼å½± ç¾å¦† å¥½ç‰© é«˜çº§ é€‚åˆ é¢œè‰² ä»Šå¤© è…®çº¢ æ—¥å¸¸\n",
      "*Topic 5\n",
      "- åˆ†äº« å¥½ç‰© ç¾å¦† å“ç‰Œ æ„Ÿè°¢ å¼€ç®± ç¤¼ç›’ æŠ¤è‚¤ å¿«ä¹ æ”¶åˆ° æœ€è¿‘ å„ä½ motd ç¤¼ç‰© ç²¾å ä¸€èµ· æ¬§è±é›… é˜¿æ–‡ å½©å¦† makeup\n",
      "*Topic 6\n",
      "- çœŸçš„ æ„Ÿè§‰ å§å¦¹ å¯ä»¥ å°±æ˜¯ æœ€è¿‘ å¤´å‘ è¿™ä¸ª èµ·æ¥ å¤å¤© ä¸€å®š ä½ ä»¬ ç®€ç›´ è¿˜æ˜¯ ç²¾è‡´ ä¸€æ · æ—¶å€™ ä»Šå¤© å–œæ¬¢ éå¸¸\n",
      "*Topic 7\n",
      "- è‡ªå·± çœŸçš„ æˆ‘ä»¬ æ²¡æœ‰ è¿™ä¸ª å¯ä»¥ å¾ˆå¤š å°±æ˜¯ è§‰å¾— ä»€ä¹ˆ çŸ¥é“ è¿˜æ˜¯ ä½ ä»¬ ç°åœ¨ ä½†æ˜¯ å¸Œæœ› å…¶å® å¤§å®¶ ä¸è¦ éå¸¸\n",
      "*Topic 8\n",
      "- å¨±ä¹ è¿·å¦¹ çœŸçš„ ç¾å¦† ç¾å‡º å“ˆå“ˆå“ˆ æ¼”å”±ä¼š è¿™æ˜¯ è¿™ä¸ª å“ˆå“ˆå“ˆå“ˆ å§å§ å¼ æ° å¬è¯´ æ€ä¹ˆ å–œæ¬¢ è¿™ä¹ˆ æ˜æ˜Ÿ èµµä¸½é¢– æš‘æœŸ å˜ç¾é€†è¢­\n",
      "*Topic 9\n",
      "- åˆ†äº« å¥½ç‰© æŠ¤è‚¤ ä»Šå¤© å¤§å®¶ ç§è‰ å¤§ä¼š å˜ç¾ æ”»ç•¥ å§å¦¹ æ¨è ä½ ä»¬ åŒå ç¾å¦† ä¸€ç§ æœ€è¿‘ æ€ä¹ˆ è‡ªå·± å¦‚ä½• çœ‹çœ‹\n",
      "*Topic 10\n",
      "- æ–°å¹´ è®¡åˆ’ å¤§å®¶ å®Œç¾ ç¤¼ç‰© å¿«ä¹ ç¤¼ç›’ ç™½é›ª è¿‡å¹´ å¿ƒåŠ¨ ä»Šæ—¥ 2022 æƒ…äººèŠ‚ ä¸€å¹´ å¼€ç®± é™å®š çº¦ä¼š è™å¹´ æ”¶åˆ° ä»Šå¤©\n",
      "*Topic 11\n",
      "- ç”Ÿæ´» æ—¥å¸¸ plog vlog ootd æ—¥è®° å¿«ä¹ ä»Šå¤© æœ€è¿‘ ç¢ç‰‡ è®°å½• çœŸçš„ åšä¸» ä½ ä»¬ å‘¨æœ« ä»€ä¹ˆ ä¸€å¤© ä»Šæ—¥ åˆ†äº« ä¸€äº›\n",
      "*Topic 12\n",
      "- æŠ¤è‚¤ çš®è‚¤ ç²¾å è‚Œè‚¤ ä¿®æŠ¤ æŠ—è€ çœŸçš„ ä¿æ¹¿ è´¨åœ° å¯ä»¥ æ•æ„Ÿ æ•ˆæœ é¢éœœ ç†¬å¤œ æˆåˆ† å¸æ”¶ æ¢å­£ åˆ†äº« çŠ¶æ€ ç´§è‡´\n",
      "*Topic 13\n",
      "- è€Œä¸” æˆ‘ä»¬ åŒæ—¶ çŠ¶æ€ ç°åœ¨ æ‰€ä»¥ å°±æ˜¯ ä½œä¸º é‡Œé¢ å¥åº· é™¤äº† é“¾æ¥ ä¸€ç›´ è¿˜æ˜¯ çŸ¥é“ æƒ³è¦ ä¿æŒ äº§å“ æ²¡æœ‰ åŠ ä¸Š\n",
      "*Topic 14\n",
      "- è¿™æ¬¡ çœŸçš„ ä½“éªŒ å¯ä»¥ æˆ‘ä»¬ è¿˜æ˜¯ è¿˜æœ‰ å¤§å®¶ ä¸ä»… çœ‹åˆ° ä¸€èµ· å…ç¨ è¿™ä¸ª æ•´ä¸ª è‡ªå·± ç›´æ¥ å°±æ˜¯ è¿™ä¹ˆ å¾ˆå¤š æ»¡æ»¡\n",
      "*Topic 15\n",
      "- æ²¡æœ‰ ä¸æ˜¯ å°±æ˜¯ çŸ¥é“ æ¯æ—¥ ä»€ä¹ˆ å¯ä»¥ ä¸€ç‚¹ ä¸€é¦™ è¿˜æ˜¯ å› ä¸º è¿™ä¸ª å¥³äºº é‚£äº› ä¸€ç“¶ ä¸–ç•Œ å¦‚æœ ä¸ä¼š å½“ç„¶ è¿™æ ·\n",
      "*Topic 16\n",
      "- ç”Ÿæ´» ä½“éªŒ è‡ªå·± ä¸€èµ· æ—¶å°š æŒ‘æˆ˜ æ„Ÿå— å¤æ—¥ è‡ªç”± å–œæ¬¢ é€ å‹ ä¸€åœº ç¾å¥½ é£æ ¼ å®šä¹‰ ä¸–ç•Œ å¯ä»¥ è‰ºæœ¯ è®¾è®¡ æµªæ¼«\n"
     ]
    }
   ],
   "source": [
    "import lda\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "def open_dict(Dict):\n",
    "    path = '%s.txt' % Dict\n",
    "    dictionary = open(path, 'r', encoding='utf-8')\n",
    "    dict = []\n",
    "    for word in dictionary:\n",
    "        word = word.strip('\\n')\n",
    "        dict.append(word)\n",
    "    return dict\n",
    "\n",
    "clearwords=open_dict('clearwords')\n",
    "\n",
    "#åˆ†è¯\n",
    "def chinese_word_cut(mytext):\n",
    "    tempcut=jieba.cut(str(mytext))\n",
    "    return \" \".join(set(tempcut)-set(clearwords))\n",
    "\n",
    "#æ‰“å°å‰n_top_wordså…³é”®è¯\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "# df = pd.read_excel(\"metoo20181221.xlsx\",'Sheet1',index_col=None,na_values=['NA'])\n",
    "# df.shape\n",
    "df[\"content_cutted\"] = df[\"å¾®åšæ­£æ–‡\"].apply(chinese_word_cut)\n",
    "n_features = 5000\n",
    "\n",
    "tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english',\n",
    "                                max_df = 0.5,\n",
    "                                min_df = 10)\n",
    "tf = tf_vectorizer.fit_transform(df.content_cutted)\n",
    "vocab=tf_vectorizer.get_feature_names_out()\n",
    "model = lda.LDA(n_topics=17, n_iter=100, random_state=1)  \n",
    "model.fit(tf)\n",
    "print('model done')\n",
    "\n",
    "#ä¸»é¢˜-å•è¯ï¼ˆtopic-wordï¼‰åˆ†å¸ƒ\n",
    "topic_word = model.topic_word_ \n",
    "print(\"shape: {}\".format(topic_word.shape))\n",
    "print(vocab[:3])\n",
    "print(topic_word[:, :3])\n",
    "for n in range(12):\n",
    "    sum_pr = sum(topic_word[n,:])  \n",
    "    print(\"topic: {} sum: {}\".format(n, sum_pr))\n",
    "\n",
    "#è®¡ç®—å„ä¸»é¢˜Top-Nä¸ªå•è¯\n",
    "import numpy as np\n",
    "n = 20\n",
    "for i, topic_dist in enumerate(topic_word):  \n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n+1):-1]  \n",
    "    print('*Topic {}\\n- {}'.format(i, ' '.join(topic_words)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3a92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
